---
title: "Market Segmentation"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

In this markdown file, we try to analyze our data and cluster it based on the customers online activity so that our client can approach the market in a more segmented fashion 

#### Loading libraries
```{r echo=FALSE, include= FALSE}
library(mvtnorm)
library(ggplot2)
#library(kmeans)q
library(LICORS)  # for kmeans++
library(foreach)
library(mosaic)
library(dplyr)

```
## EDA on DATA:
#### Plotting summaries and checking for null values in each of the columns
```{r echo = FALSE}
## Reading the file and checking its characterstics : 
ms <- read.csv("social_marketing.csv")
#Checking for na values 
msna<- ms[which(is.na(ms)==TRUE),]
msna
check1 = nrow(ms)
check2 = length(unique(ms$X))
if( check1 == check2){
  print("unique ids")
}
## Checking for na values again 
for(i in 2:nrow(ms)){
  for(j in 1:ncol(ms)){
    if(is.na(ms[i,j]) == TRUE){
      print("Yes")
    }
  }
}
print(summary(ms))
```
There are no null values 
There are no duplicate ids 
Based on the summary above, it looks like the range, median and mean of the columns in my data are more or less the same, except for spam, dating and adult
#### Plotting frequency distribution across categories
```{r echo = FALSE}
brex = data.frame()
for (i in 2:ncol(ms)){
  brex[(i-1),1] = names(ms[i])
  brex[(i-1),2] = sum(ms[,i])
}
#brex[[1]] <- NULL
#ggplot(data )
colnames(brex) <- c('Column_Name','value')
ggplot(brex, mapping = aes(x=Column_Name,y=value))+
  geom_bar(stat = 'identity')+
  theme(axis.text.x = element_text(angle=90, vjust=0.6))
```
#### Plotting some scatter plots to see if there are any good amount of outliers present in my data which can effect the clustering 
```{r echo = FALSE}
i = 0
par(mfrow=c(3,3))
for( i in 2:ncol(ms)){
  #plot(ms[,i], xlab = colnames(ms[i]), ylab = colnames(ms[i]))
  hist(ms[,i], xlab = colnames(ms[i]), main = "")
}
#ms$id <-   NULL
```
Based on the plots and summary above, we can see that the range of my columns are more or less the same, also there are no such bunch of outliers present which can hamper my clustering, so it would not be a waste of time to run clustering on unscaled data as well
We can also try iterations with removing spam and adult variables 
## PROCEDURE: 
Post EDA, following models were tried : 
 - Kmeans 
 - Heirarchical Clustering 
 - Kmeans++
 - RUnning the above three on PCA components
 
Each of the above Iteration were tried on SCALED DATA, UNSCALED DATA and NORMALIZED DATA (Reason written in EDA section)
 
For every iteration, the optimum number of clusters were determined (K) by guessing a range from "Elbow Curve" plots, "CH Index" plots and GAP Statistics. 
After running through each value of K, the properties of cllusters were determined by ploting boxplots of every variable across each cluster. Suppose the median,upper range and lower range of a particular cluster for a particular variable was coming out to be significantly high or low, we used to assign a property based on the variable to that cluster. For example, after running an iteration of Kmeans with K = 5, and plotting box plots of all the 5 clusters across a variable "travel", my second cluster's box plot had higher values, we would say people in cluster 2 generally tend to comment more on travel related categories
After running these methods, certain scatter plots were drawn to see how distinctly we are able to identify the clusters
Based on the distribution of data across clusters, business use case and extent of distinction, few of the following models are chosen.
## K means on scaled data with K = 7
#### For the scaled data running K-means 
#### Plotting an elbow curve  
```{r echo = FALSE,warning=FALSE}
# checking for K values from 1 to 20 
ms1 = scale(ms[,2:ncol(ms)])
sd = list()
set.seed(1234)
for(i in 1:20){
  
  clusterk = kmeans(ms1,i, nstart = 1) # nstart = number of times you want to run the kmean : will run the kmean k=n times and give you the result based on minimum total withiness 
  sd[i] = clusterk$tot.withinss
  #print(i)
}
plot(seq(1:20),sd)
```
#### Plotting with CH Index
```{r echo=FALSE, warning=FALSE}
# checking for K values from 1 to 20 
set.seed(1234)
ms1 = scale(ms[,2:ncol(ms)])
sd = list()
n = nrow(ms1)
for(i in 1:20){
  
  clusterk = kmeans(ms1,i, nstart = 1)
  sd[i] = (clusterk$betweenss/clusterk$tot.withinss)*((n-i)/(i-1))
  #print(i)
}
plot(seq(1:20),sd)
```
#### Plotting GAP Statistics
```{r echo = FALSE, warning=FALSE}
set.seed(1234)
library(cluster)
ms_gap = clusGap(ms1, FUN = kmeans, nstart = 5, K.max = 15, B = 10)
plot(ms_gap)
```

#### Trying different iterations and running K means with 7

```{r echo = FALSE, warning=FALSE}
set.seed(1234)
clust1 = kmeans(ms1, 7, nstart=25)
#plot(clust1$tot.withinss)
msc <- cbind(ms,clust1$cluster)
#View(msc)
msc$clust <- msc$`clust1$cluster`
msc$`clust1$cluster` <- NULL
msc$clustF <- as.factor(msc$clust)
msc$id <- row.names(ms)
## The following code is used for plotting bar plot of clusters 
msctest <- msc
msctest$dummy <- 1
mscclst = msctest %>% 
  group_by(clustF) %>%
  summarise(den.sum = sum(dummy))
ggplot(mscclst, mapping = aes(x=clustF,y=den.sum))+
  geom_bar(stat = 'identity')+
  xlab("Cluster Number") +
  ylab("Frequency")
  #theme(axis.text.x = element_text(angle=90, vjust=0.6))
```
#### Plotting box plots
```{r echo = FALSE, warning=FALSE}
par(mfrow=c(2,3))
#boxplot( msc$clustF,msc$food)
for ( i in 2:37){
plot(msc$clustF, msc[,i], ylab = names(msc[i]))
}
```
Based on the plots above we can bucket aur audience into following audience: 
Class 1(Trendy class) : These people generally talk about fashion, beauty, pic sharing and cooking generally.
Class 2(Technical and knowledge sharing) : Automative, computers, news, politics and travel are topics generally discussed 
Class 3(Health Conscious) : Personal Fitting, outdoor, health_nutrition and food (might be discussing about healthy food and suppliments)
Class 4(Family persons): School, parenting, religion, family, food and sports fandom
Class 5(Instagram People): Shopping, TV Films, shopping, pic sharing and chatter
Class 7(College people) : Arts, sports_playing, college_uni and online gaming 
```{r echo= FALSE, warning=FALSE}
# for( i in 2:8){
#   l = i+1
#   for( j in l:10){
# 
# print(qplot(msc[,i], msc[,j], data=msc, color=msc$clustF, xlab = names(msc[i]), ylab = names(msc[j])))
#   }
# }
mscplot <- msc
mscplot$id <- msc$X #row.names(mscplot)
par(mfrow =c(2,3))
print(qplot((msc[,33]), (msc[,17]), data=msc, color=msc$clustF, xlab = names(msc[33]), ylab = names(msc[17])))
print(qplot(msc[,34], msc[,29], data=msc, color=msc$clustF, xlab = names(msc[34]), ylab = names(msc[29])))
print(qplot(msc[,15], msc[,18], data=msc, color=msc$clustF, xlab = names(msc[15]), ylab = names(msc[18])))
print(qplot(msc[,30], msc[,28], data=msc, color=msc$clustF, xlab = names(msc[30]), ylab = names(msc[28])))
```
In first plot we can see how our class 3 ( health conscious) tend to post most about health nutirition and personal fitness
Second plot shows majority of our class 1 population talking about beauty 
Third plot shows our college people talking about college_uni and online gaming
Forth plot shows our "Family Person" class 4 talking majorly about religion and parenting
## Kmeans++ on unscaled data with K = 12
#### Have removed columns adult and spam
```{r echo=FALSE, warning=FALSE}

# checking for K values from 1 to 20 
ms2 = (ms[,2:ncol(ms)])
ms2$adult <- NULL
ms2$spam <- NULL
sd = list()

#ms2 <- (ms4)
set.seed(1234)
for(i in 1:20){
  
  clusterk = kmeanspp(ms2,i, nstart = 1) # nstart = number of times you want to run the kmean : will run the kmean k=n times and give you the result based on minimum total withiness 
  sd[i] = clusterk$tot.withinss
  #print(i)
}
plot(seq(1:20),sd)
```
#### Plotting with CH Index
```{r echo= FALSE, warning=FALSE}
# checking for K values from 1 to 20 
set.seed(1234)
#ms2 = (ms[,2:ncol(ms)])
sd = list()
n = nrow(ms2)
set.seed(1234)
for(i in 1:20){
  
  clusterk = kmeanspp(ms2,i, nstart = 1)
  sd[i] = (clusterk$betweenss/clusterk$tot.withinss)*((n-i)/(i-1))
  #print(i)
}
plot(seq(1:20),sd)
```
## Plotting using Gap Statistics 
```{r echo=FALSE, warning=FALSE}
library(cluster)
set.seed(1234)
ms_gap = clusGap(ms2, FUN = kmeanspp, nstart = 5, K.max = 15, B = 10)
plot(ms_gap)
```
#### Kmeanspp for K = 12
```{r echo = FALSE, warning=FALSE}
set.seed(1234)
mspp <- ms2
mspp$adult <- NULL
mspp$spam <- NULL
mspp$uncategorized <- NULL
mspp <- scale(mspp[2:ncol(mspp)])
mspc <- data.frame(mspp)
clust1 = kmeanspp(mspp, 12 , nstart=25)
#plot(clust1$tot.withinss)
msc <- cbind(ms,clust1$cluster)
#View(msc)
msc$clust <- msc$`clust1$cluster`
msc$`clust1$cluster` <- NULL
msc$clustF <- as.factor(msc$clust)
msc$id <- row.names(ms)
#for ( i in 2:10){
  
## The following code is used for plotting bar plot of clusters 
msctest <- msc
msctest$dummy <- 1
mscclst = msctest %>% 
  group_by(clustF) %>%
  summarise(den.sum = sum(dummy))
ggplot(mscclst, mapping = aes(x=clustF,y=den.sum))+
  geom_bar(stat = 'identity')
  #theme(axis.text.x = element_text(angle=90, vjust=0.6))
```
#### Plotting box plots
```{r echo = FALSE}
#boxplot( msc$clustF,msc$food)
for ( i in 2:37){
plot(msc$clustF, msc[,i], ylab = names(msc[i]))
}
```
Based on the model above we can segment our audience into following categories: 
- Class 1 ( College people) : They usually talk about playing sports, online gaming and college uni 
- Class 2 (Shopping enthu) : They are high in topics realted to shopping, pic sharing and chatter
- Class 3 (Artistic) : Art and tv_films are generally topics of discussion 
- Class 4( Health Freaks) : personal_fitness, outdoors, health_nutrition
- Class 5( Tech and news) : Computers, news ,politics and travel are majority topics
- Class 6( Family people) : Parenting, Family and religion
- Class 7 : Fashion, Beauty, Cooking and Photo Sharing
- Class 9( Teenage) : Topics of discussion are school, dating and chatter 
- Class 10 (Family People): School, Parenting, Family, Religion, food, sports_fandon
- Class 12 (News) : Automotive, news and politics 
#### Drawing some scatter plots
```{r echo= FALSE, warning=FALSE}

mscplot <- msc
mscplot$id <- msc$X #row.names(mscplot)
par(mfrow =c(2,3))
#qplot( row.names(mscplot),  mscplot$personal_fitness,colour =msc$clustF)
print(qplot((msc[,33]), (msc[,17]), data=msc, color=msc$clustF, xlab = names(msc[33]), ylab = names(msc[17])))
print(qplot(msc[,34], msc[,29], data=msc, color=msc$clustF, xlab = names(msc[34]), ylab = names(msc[29])))
print(qplot(msc[,15], msc[,18], data=msc, color=msc$clustF, xlab = names(msc[15]), ylab = names(msc[18])))
print(qplot(msc[,11], msc[,28], data=msc, color=msc$clustF, xlab = names(msc[11]), ylab = names(msc[28])))
print(qplot(msc[,30], msc[,28], data=msc, color=msc$clustF, xlab = names(msc[30]), ylab = names(msc[28])))
```
In the first plot we can see our Class 3 being dominant as they are health freak people 
In the second plot we can see people from Class 7 talking about beauty and fashion 
In the third plot we see our students pots
In fourth plot and fifth plot we can see lot of class 8 and 6 people but class 8 is dominant
##CONCLUSION: 
 After iterating over several techniques and parameters, above two gave the best resuts. However, the problem in both cases is that we are unable to classify properly the class which has major chunk of data in it. 
 
 We evaluated clusters based on the box plots and scatter plots. 
 
 In 1st method, the mojrity chunk in which we were unable to cluster them properly consisted of 3500 records , but for the ones we did, we could show for attributes attached to those classes, majority of the data points in their scatter plot belonged to them. 
 
 In 2nd method, we were unable to give good properties to cluster 8. For cluster 6, some properties were getting tied up to it but i scatter plots we saw that those properties were getting overshadowed due to other classes, so we can say the model did not clustered by class 6 properly. Thus there are total 4500 which do not have any specific property.
Thus we will go with 1st model and classify our audience accordingly.
